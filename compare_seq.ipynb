{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 序列比对工具\n",
    "\n",
    "## 说明\n",
    "\n",
    "* 将需要检查的文件上传/copy 到指定的目录下. 默认是在 demo目录\n",
    "* 按照下面的要求指定所需的参数\n",
    "* 在菜单中选择Cell -> Run All\n",
    "* 整理后的文件将保存在指定的目录下, 以csv方式保存. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件参数\n",
    "\n",
    "* 原始数据文件的存放路径: input_path\n",
    "* 最终比对结果的存放路径: output_path\n",
    "* 比对用的源文件: \"source\":docx_name\n",
    "* 比对用的目标文件: \"target\":txt_name\n",
    "\n",
    "注意, 源文件中的序列是目标文件序列的**子集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:38.713321Z",
     "start_time": "2017-11-12T09:15:38.696696Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    input_path='demo'\n",
    "    output_path='demo'\n",
    "    \n",
    "    docx_name='AAA.docx'\n",
    "    txt_name='BBB.txt'\n",
    "    \n",
    "#     docx_name='AAA_F.docx' # 阳性测试\n",
    "#     txt_name='BBB_F.txt'   # 阳性测试\n",
    "    \n",
    "    source_target_dict={\"source\":docx_name,\n",
    "                        \"target\":txt_name}\n",
    "#     source_target_dict={\"source\":txt_name,\n",
    "#                         \"target\":docx_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 内容参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docx文件类型中, 需要指定每个表格的内容参数\n",
    "* head: 表头所占的行数\n",
    "* seqtype: 序列的类型, 是chain, 还是CDR\n",
    "* chaintype: chain的type, 是重链HeavyChain还是轻链LightChain, 注意如果是CDR, 用HC/LC标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:38.724618Z",
     "start_time": "2017-11-12T09:15:38.716071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    table_catalog_dict={\n",
    "        0: {\"head\": 1, \"seqtype\":'chain', \"chaintype\":'HeavyChain'},\n",
    "        1: {\"head\": 1, \"seqtype\":'chain', \"chaintype\":'LightChain'},\n",
    "        2: {\"head\": 2, \"seqtype\":'CDR', \"chaintype\":'HC'}, \n",
    "        3: {\"head\": 2, \"seqtype\":'CDR', \"chaintype\":'LC'}, \n",
    "        4: {\"head\": 1, \"seqtype\":'chain', \"chaintype\":'HeavyChain'},\n",
    "        5: {\"head\": 1, \"seqtype\":'chain', \"chaintype\":'LightChain'},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TXT文件中, 需要指定名称中的关键词\n",
    "\n",
    "在txt文件中, 需要根据ID的名称判断序列的类型, 因此需要使用下面的字典进行指定, 例如: \n",
    "名称中包含有\"Heavy\",\"heavy\",\"VH\",\"vh\" 都将被识别成HeavyChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:38.733341Z",
     "start_time": "2017-11-12T09:15:38.727461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "#     marker_words_dict={\n",
    "#         \"HeavyChain\":[\"Heavy\",\"heavy\",\"VH\",\"vh\"],\n",
    "#         \"LightChain\":[\"Light\",\"light\",\"VL\",\"vl\"],\n",
    "#         \"HCCDR1\":[\"HC CDR1\"],\n",
    "#         \"HCCDR2\":[\"HC CDR2\"],\n",
    "#         \"HCCDR3\":[\"HC CDR3\"],\n",
    "#         \"LCCDR1\":[\"LC CDR1\"],\n",
    "#         \"LCCDR2\":[\"LC CDR2\"],\n",
    "#         \"LCCDR3\":[\"LC CDR3\"],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入依赖包\n",
    "\n",
    "在azure notebook上运行时, 由于远程服务器在1小时后会自动关闭并清除所有安装内容, 所以临时安装的依赖软件包并不能正常加载. 需要使用服务器上的预制程序进行设置: \n",
    "建立script.txt文件: \n",
    "```txt\n",
    "export PATH=~/anaconda3_410/bin:$PATH\n",
    "conda install -c anaconda biopython --yes\n",
    "pip install python-docx\n",
    "```\n",
    "然后在setting中加载. 这样每次启动azure notebook时会自动安装biopython和python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.035914Z",
     "start_time": "2017-11-12T09:15:38.736139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas包, 需安装\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# python-docx包, 需安装\n",
    "from docx import Document\n",
    "\n",
    "# biopython包, 需安装\n",
    "from Bio.SeqUtils import seq1\n",
    "\n",
    "# 系统自带包, 无需安装\n",
    "from collections import OrderedDict # 有序字典\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 自建包\n",
    "from save_sequence import save_seq_to_csv \n",
    "# from readDOC import read_sequence_from_docx\n",
    "# from readTXT import read_sequence_from_TXT\n",
    "from reconstruct_TXT import reconstruct_TXT\n",
    "from reconstruct_DOC import reconstruct_DOC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取文件\n",
    "\n",
    "文件通过两个程序读入: \n",
    "* read_sequence_from_docx 用于读取docx文件, \n",
    "* read_sequence_from_txt 用于读取txt文件\n",
    "\n",
    "由于可能调换source文件和target文件的对应方式, 所以使用了字典source_target_dict来记录对应关系. \n",
    "使用文件名的末尾3位来判断文件的类型, 是docx/txt\n",
    "\n",
    "文件读取后经过清理, 转换成pandas DataFrame的数据形式进行操作处理. 并且将转换后的DataFrame保存为**同名csv文件**, 存放在output_path文件夹之下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.072103Z",
     "start_time": "2017-11-12T09:15:40.038129Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            ):\n",
    "#     docx_df=read_sequence_from_docx(input_path,docx_name,output_path,table_catalog_dict)\n",
    "#     txt_df=read_sequence_from_TXT(input_path,txt_name,output_path,marker_words_dict)\n",
    "    docx_df=reconstruct_DOC(input_path,docx_name,output_path,table_catalog_dict)\n",
    "    txt_df= reconstruct_TXT(input_path,txt_name,output_path)\n",
    "    source_name=source_target_dict[\"source\"]\n",
    "    target_name=source_target_dict[\"target\"]\n",
    "\n",
    "    if (source_name[-3:].lower()==\"ocx\" or source_name[-3:].lower()==\"doc\") and target_name[-3:].lower()==\"txt\":\n",
    "        source_df=docx_df\n",
    "        target_df=txt_df\n",
    "    elif source_name[-3:].lower()==\"txt\" and (source_name[-3:].lower()==\"ocx\" or source_name[-3:].lower()==\"doc\") :\n",
    "        source_df= txt_df\n",
    "        target_df= docx_df\n",
    "    return (source_df,target_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.309841Z",
     "start_time": "2017-11-12T09:15:40.074861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NAME                                           SEQUENCE   CHAINTYPE  ID\n",
      "0  CJK42  QSSRRSQQQQQQQQQQLSSSSSPPPPSSSSGLGGGRRRAAAMMMMM...  HeavyChain   1\n",
      "0  CJK42  QQQQSSQQQQQNNDDDLLLLSLDDLLLLLLLLMMMMMMMMMMMMMM...  LightChain   2\n",
      "0  CJK42                                              SSRRS      HCCDR1   3\n",
      "0  CJK42                                     SSSSSPPPPSSSSG      HCCDR2   4\n",
      "   ID   NAME                                           SEQUENCE   CHAINTYPE\n",
      "1   1  CJK42  QSSRRSQQQQQQQQQQLSSSSSPPPPSSSSGLGGGRRRAAAMMMMM...  HeavyChain\n",
      "2   2  CJK42  QQQQSSQQQQQNNDDDLLLLSLDDLLLLLLLLMMMMMMMMMMMMMM...  LightChain\n",
      "3   3  CJK42                                              SSRRS      HCCDR1\n",
      "4   4  CJK42                                     SSSSSPPPPSSSSG      HCCDR2\n"
     ]
    }
   ],
   "source": [
    "# 以下为文件读取方面的测试\n",
    "# 应当输出两个数据表格\n",
    "if __name__==\"__main__\":\n",
    "    # 读取文件\n",
    "    (source_df,target_df)=read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )\n",
    "    # 测试读取文件\n",
    "    print(source_df.iloc[0:4])\n",
    "    print(target_df.iloc[0:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件内部序列比对\n",
    "CDR序列是否出现在chain序列中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数is_find\n",
    "函数is_find表示是否可以找到有chain序列包含CDR序列, \n",
    "输入部分是: \n",
    "* 被检查的数据表df_2check,\n",
    "* CDR的ID编号\n",
    "* CDR的类型, 可能是HC/LC CDR 1/2/3共6种之一\n",
    "* 被检查的chain类型, HCCDR对应检查的是HeavyChain. 以此类推\n",
    "如果能够在chain序列中找到, 就返回True, 否则返回False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.388653Z",
     "start_time": "2017-11-12T09:15:40.312823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_find(df_2check,checker_name,checker_type,target_type):\n",
    "    \n",
    "    # 根据checker_ID找到chain和CDR的序列集合, 交给一个数据表df_checker_and_target\n",
    "    # 例如ID=\"C8\"的序列包含有C8的HeavyChain, LightChain, HCCDR123, LCCDR123\n",
    "    df_checker_and_target = df_2check.loc[df_2check[\"NAME\"]==checker_name]\n",
    "    \n",
    "    # 根据checker_type 和 target_type 分别找到checker的条目和target的条目\n",
    "    checker_item=df_checker_and_target[ df_checker_and_target['CHAINTYPE']==checker_type ]\n",
    "    target_item=df_checker_and_target[ df_checker_and_target['CHAINTYPE']==target_type ]\n",
    "    \n",
    "    # 要取得checker内所包含的序列字符串, 目前没有发现更优雅的方式,\n",
    "    # 理论上DataFrame是和numpy的array等效, 所以可以用list强行转换, \n",
    "    # list中只有一个项目, 所以用[0]提取出来\n",
    "    if  type(checker_item) != pd.core.frame.DataFrame :\n",
    "        return False\n",
    "\n",
    "    \n",
    "    checker_seq=list(checker_item[\"SEQUENCE\"])[0] #WTF\n",
    "    \n",
    "    # dataframe.str.find是在字符串中寻找checker_seq的位置, 如果没有发现, 位置就返回为-1\n",
    "    # 返回的数值也是以dataframe object的形式存储\n",
    "    result = (target_item[\"SEQUENCE\"].str.find(checker_seq)>=0)\n",
    "    \n",
    "    # 偶尔会出现不明原因的bug, 导致result中没有任何结果, 也就是一个空list\n",
    "    # 判断一个list是否为空, 可以使用not list( )的方法\n",
    "    if not list(result):\n",
    "        res=False\n",
    "    else:\n",
    "        res=list(result)[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数check_CDR_in_seq\n",
    "检查数据表df_2check中, 是否每一个CDR都能找到对应的chain\n",
    "* 首先从HCCDR123, LCCDR123中选择1个类别的CDR, 例如HCCDR1\n",
    "* 根据配对字典找到其对应的被检查类别, 例如HeavyChain\n",
    "* 然后依次遍历该CDR种类下所有的项目, 使用is_find函数进行查找\n",
    "\n",
    "最终返回结果以pandas dataframe的形式进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.481925Z",
     "start_time": "2017-11-12T09:15:40.391668Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_CDR_in_seq(df_2check):\n",
    "    # 配对检查字典\n",
    "    check_pair_dict={\n",
    "    \"HCCDR1\":\"HeavyChain\",\n",
    "    \"HCCDR2\":\"HeavyChain\",\n",
    "    \"HCCDR3\":\"HeavyChain\",\n",
    "    \"LCCDR1\":\"LightChain\",\n",
    "    \"LCCDR2\":\"LightChain\",\n",
    "    \"LCCDR3\":\"LightChain\"\n",
    "    }\n",
    "    \n",
    "    # 检查结果先暂时存放在list中, 最后再转换成DataFrame\n",
    "    check_result=list()\n",
    "    \n",
    "    # 遍历每一种CDR检查类型\n",
    "    for checker_type in check_pair_dict.keys():\n",
    "        target_type=check_pair_dict.get(checker_type)\n",
    "        checker_name_list=df_2check[ df_2check[\"CHAINTYPE\"]==checker_type ].NAME\n",
    "        \n",
    "    # 遍历检查类型中的每一个ID, 同一ID下会有多个序列, \n",
    "    # 例如ID=\"C8\"时, C8 HCCDR1/ C8 HCCDR2/ C8 HCCDR3 /C8 Heavychain/ C8 Lightchain\n",
    "        for checker_name in checker_name_list:\n",
    "            # 交给is_find函数检查\n",
    "            if is_find(df_2check,checker_name,checker_type,target_type)==False:\n",
    "                \n",
    "                # 单独提取出异常的checker存入列表中\n",
    "                give_out=df_2check.loc[df_2check[\"NAME\"]==checker_name]\n",
    "                give_out=give_out[ give_out [\"CHAINTYPE\"]==checker_type ]\n",
    "                check_result.append(give_out)\n",
    "#                 print(give_out)\n",
    "    # 返回结果中如果是空列表, 就返回空的DataFrame\n",
    "    if not check_result: # check list isempty\n",
    "        result=DataFrame() # 此处不可直接使用pd.concat, 否则报错\n",
    "    else:\n",
    "        result=DataFrame(pd.concat(check_result))\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.746816Z",
     "start_time": "2017-11-12T09:15:40.483993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAA.docx文件中, 不能找到对应序列的有:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "BBB.txt文件中, 不能找到对应序列的有:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # 读取文件\n",
    "    (source_df,target_df)=read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )    \n",
    "    #文件内部比对\n",
    "    df_2check=source_df\n",
    "    source_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    print(\"\\n{0}文件中, 不能找到对应序列的有:\".format(source_target_dict[\"source\"]))\n",
    "    print(source_df_check_result) \n",
    "\n",
    "    df_2check=target_df\n",
    "    target_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    print(\"\\n{0}文件中, 不能找到对应序列的有:\".format(source_target_dict[\"target\"]))\n",
    "    print(target_df_check_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件之间的序列比对"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有source文件中的序列, 都应当出现在target文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:40.808796Z",
     "start_time": "2017-11-12T09:15:40.749471Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_seq_between(source_df,target_df):\n",
    "    # 这里希望一并检查ID, SEQUENCE和CHAINTYPE, 因此重置了index, 使得ID也作为column\n",
    "    newsource_df=source_df.reset_index()\n",
    "    newtarget_df=target_df.reset_index()\n",
    "    \n",
    "    # 结果先暂存至list中\n",
    "    result_list=list()\n",
    "    \n",
    "    # 遍历source数据表中的每一项, 去target数据表中查询\n",
    "    for iloc in range(newsource_df.shape[0]) :\n",
    "        source_item = newsource_df.iloc[iloc]\n",
    "        # 遍历查询比较, 将返回一个数据表, 每一项中以True/False标记是否相同\n",
    "        same_item=newtarget_df[newtarget_df==source_item]\n",
    "        \n",
    "        if source_item[\"ID\"] <=0 : # 如果没有合适的ID, 会使用负数作为标记. \n",
    "        # 提取出所有\"SEQUENCE\"为真 并且 \"chaintype\" 为真的项目\n",
    "            tf=any ( # pd.notnull(same_item[\"ID\"]) &  # 当没有合适ID时, 则不比较ID\n",
    "                     pd.notnull(same_item[\"SEQUENCE\"]) & \n",
    "                     pd.notnull(same_item[\"CHAINTYPE\"]) ) \n",
    "        else:\n",
    "            tf=any ( pd.notnull(same_item[\"ID\"]) &  # 只在有合适ID时, 才比较ID\n",
    "                    pd.notnull(same_item[\"SEQUENCE\"]) & \n",
    "                    pd.notnull(same_item[\"CHAINTYPE\"]) ) \n",
    "        if tf==False:\n",
    "            result_list.append(source_item)\n",
    "            \n",
    "    if not result_list:\n",
    "        result=DataFrame()\n",
    "    else:\n",
    "        result=pd.concat(result_list)\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:41.105382Z",
     "start_time": "2017-11-12T09:15:40.811923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAA.docx文件中, 不能找到对应序列的有:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "BBB.txt文件中, 不能找到对应序列的有:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "在源文件AAA.docx文件中, 不能找到对应序列的有:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # 读取文件\n",
    "    (source_df,target_df)=read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )    \n",
    "    # 文件内部比对\n",
    "    df_2check=source_df\n",
    "    source_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    print(\"\\n{0}文件中, 不能找到对应序列的有:\".format(source_target_dict[\"source\"]))\n",
    "    print(source_df_check_result) \n",
    "\n",
    "    df_2check=target_df\n",
    "    target_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    print(\"\\n{0}文件中, 不能找到对应序列的有:\".format(source_target_dict[\"target\"]))\n",
    "    print(target_df_check_result)\n",
    "    \n",
    "    # 文件之间的比对\n",
    "    result_df=check_seq_between(source_df,target_df)\n",
    "    print(\"\\n在源文件{0}文件中, 不能找到对应序列的有:\".format(source_target_dict[\"source\"]))\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:41.213512Z",
     "start_time": "2017-11-12T09:15:41.108638Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explain_result(source_df_check_result,target_df_check_result,result_df,output_path):\n",
    "    explain=\"\"\n",
    "    explain +=(\"被检查的文件有: \\n源文件为:\\t{0}\\n目标文件为:\\t{1}\".format(source_target_dict[\"source\"],source_target_dict[\"target\"]))\n",
    "    explain +=\"\\n\"+\"=\"*50+\"\\n\"\n",
    "    explain +=(\"检查CDR是否出现在相应的序列中: \\n\")\n",
    "    explain +=(\"在源文件{0}中, \".format(source_target_dict[\"source\"]))\n",
    "\n",
    "    if source_df_check_result.shape[0]==0:\n",
    "        explain+=(\"未发现异常\\n\")\n",
    "    else:\n",
    "        explain+=\"存在 {0} 条异常序列: \\n\".format(source_df_check_result.shape[0])\n",
    "        explain+=(str(source_df_check_result))\n",
    "        explain +=\"\\n\"+\"=\"*50+\"\\n\"\n",
    "\n",
    "\n",
    "    explain+=(\"\\n在目标文件{0}中, \".format(source_target_dict[\"target\"]))\n",
    "\n",
    "    if target_df_check_result.shape[0]==0:\n",
    "        explain+=(\"未发现异常\\n\")\n",
    "    else:\n",
    "        explain+=\"存在 {0} 条异常序列: \\n\".format(target_df_check_result.shape[0])\n",
    "        explain+=(str(target_df_check_result))\n",
    "        explain +=\"\\n\"+\"=\"*50+\"\\n\"\n",
    "\n",
    "\n",
    "    explain +=(\"\\n检查源文件{0}中的序列是否都出现在目标文件{1}中: \\n\").format(source_target_dict[\"source\"],source_target_dict[\"target\"])\n",
    "    if result_df.shape[0]==0:\n",
    "        explain+=(\"未发现异常\\n\")\n",
    "    else:\n",
    "        explain+=\"存在 {0} 条异常序列: \\n\".format(result_df.shape[0]/5)\n",
    "        explain+=(str(DataFrame(result_df)))\n",
    "        explain +=\"\\n\"+\"=\"*50+\"\\n\"\n",
    "\n",
    "    explain +=\"\\n\"\n",
    "    report_filename=os.path.join(output_path,\"report.txt\")\n",
    "    f=open(report_filename,'w')\n",
    "    f.write(explain)\n",
    "    return explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:41.456945Z",
     "start_time": "2017-11-12T09:15:41.215955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被检查的文件有: \n",
      "源文件为:\tAAA.docx\n",
      "目标文件为:\tBBB.txt\n",
      "==================================================\n",
      "检查CDR是否出现在相应的序列中: \n",
      "在源文件AAA.docx中, 未发现异常\n",
      "\n",
      "在目标文件BBB.txt中, 未发现异常\n",
      "\n",
      "检查源文件AAA.docx中的序列是否都出现在目标文件BBB.txt中: \n",
      "未发现异常\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # 读取文件\n",
    "    (source_df,target_df)=read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )    \n",
    "    # 文件内部比对\n",
    "    df_2check=source_df\n",
    "    source_df_check_result=check_CDR_in_seq(df_2check)\n",
    "\n",
    "    df_2check=target_df\n",
    "    target_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    \n",
    "    # 文件之间的比对\n",
    "    result_df=check_seq_between(source_df,target_df)\n",
    "    \n",
    "    # 生成报告\n",
    "    report=explain_result(source_df_check_result,target_df_check_result,result_df,output_path)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整理封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:41.510366Z",
     "start_time": "2017-11-12T09:15:41.463426Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_sequence(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            ):\n",
    "    # 读取文件\n",
    "    (source_df,target_df)=read_source_target_file(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )\n",
    "    \n",
    "    # 文件内部比对\n",
    "    df_2check=source_df\n",
    "    source_df_check_result=check_CDR_in_seq(df_2check)\n",
    "\n",
    "    df_2check=target_df\n",
    "    target_df_check_result=check_CDR_in_seq(df_2check)\n",
    "    \n",
    "    # 文件之间的比对\n",
    "    result_df=check_seq_between(source_df,target_df)\n",
    "    \n",
    "    # 生成报告\n",
    "    report=explain_result(source_df_check_result,target_df_check_result,result_df,output_path)\n",
    "    print(report)\n",
    "    return (source_df_check_result,target_df_check_result,result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T09:15:41.784853Z",
     "start_time": "2017-11-12T09:15:41.515829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被检查的文件有: \n",
      "源文件为:\tAAA.docx\n",
      "目标文件为:\tBBB.txt\n",
      "==================================================\n",
      "检查CDR是否出现在相应的序列中: \n",
      "在源文件AAA.docx中, 未发现异常\n",
      "\n",
      "在目标文件BBB.txt中, 未发现异常\n",
      "\n",
      "检查源文件AAA.docx中的序列是否都出现在目标文件BBB.txt中: \n",
      "未发现异常\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    compare_sequence(input_path,output_path,docx_name,txt_name,\n",
    "                            source_target_dict,\n",
    "                            table_catalog_dict,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "322px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
